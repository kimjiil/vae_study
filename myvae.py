# -*- coding: utf-8 -*-
"""myvae.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1oVd_bxaaAjQS17xLgUur9ItukSwALqPE
"""

import torchvision
import torch
import torch.nn as nn
from torchvision import transforms
import matplotlib.pyplot as plt
import numpy as np

train_transform = transforms.Compose([
    transforms.ToTensor()
])

valid_transform = transforms.Compose([
    transforms.ToTensor()
])

train_dataset = torchvision.datasets.MNIST('./', train=True, transform=train_transform, download=True)
valid_dataset = torchvision.datasets.MNIST('./', train=False, transform=valid_transform, download=True)

train_data = train_dataset.train_data # 60000 x 28 x 28
train_label = train_dataset.train_labels # 60000

valid_data = valid_dataset.test_data # 10000 x 28 x 28
valid_label = valid_dataset.test_labels # 10000

class VAE(torch.nn.Module):
    def __init__(self):
        super(VAE, self).__init__()

        self.encoder = nn.Sequential(
            # input 1x28x28
            nn.Conv2d(in_channels=1, out_channels=4, kernel_size=3, stride=2, padding=1), 
            nn.BatchNorm2d(4),
            nn.LeakyReLU(),
            # 4x14x14
            nn.Conv2d(in_channels=4, out_channels=8, kernel_size=3, stride=2, padding=1),
            nn.BatchNorm2d(8),
            nn.LeakyReLU(),
            # 8x7x7
            nn.Conv2d(in_channels=8, out_channels=16, kernel_size=3, stride=2, padding=1),
            nn.BatchNorm2d(16),
            nn.LeakyReLU(),
            # 16x4x4
            nn.Flatten()
            # output 1x256
        )

        self.mu_layer = nn.Sequential(
            nn.Linear(in_features=256, out_features=64),
            nn.Linear(in_features=64, out_features=16),
            nn.Linear(in_features=16, out_features=2)
        )

        self.std_layer = nn.Sequential(
            nn.Linear(in_features=256, out_features=64),
            nn.Linear(in_features=64, out_features=16),
            nn.Linear(in_features=16, out_features=2)
        )

        self.z_layer = nn.Sequential(
            nn.Linear(in_features=2, out_features=16),
            nn.Linear(in_features=16, out_features=64),
            nn.Linear(in_features=64, out_features=256)
        )

        #convTranpose output dim = (dim_in - 1) x stride - 2 x padding + dilation x (kernel_size - 1)
        self.decoder = nn.Sequential(
            nn.Unflatten(1, (16, 4, 4)),
            nn.ConvTranspose2d(in_channels=16, out_channels=8, kernel_size=3, stride=2, padding=1),
            nn.BatchNorm2d(8),
            nn.LeakyReLU(),

            nn.ConvTranspose2d(in_channels=8, out_channels=4, kernel_size=4, stride=2, padding=1),
            nn.BatchNorm2d(4),
            nn.LeakyReLU(),

            nn.ConvTranspose2d(in_channels=4, out_channels=1, kernel_size=4, stride=2, padding=1),
            nn.Sigmoid()
            # output 1x28x28
        )

    def forward(self, x):
        x = self.encode(x)
        mu = self.mu_layer(x)
        std = self.std_layer(x)

        z = self.reparameterize(mu, std)
        z = self.z_layer(z)

        x = self.decode(z)

        return x, mu, std

    def reparameterize(self, mu, std):

        e = torch.normal(0, 1, size=mu.size()).cuda()
        z = mu + e * std
        return z
    
    def encode(self, x):
        return self.encoder(x)

    def decode(self, x):
        return self.decoder(x)

bce_loss = torch.nn.BCELoss(reduction='mean')

def loss_func(input, output, mu, std):
    # marginal_likelihood = torch.mean(torch.sum(input * torch.log(output) + (1-input) * torch.log(1-output), dim=(1, 2, 3)))
    marginal_likelihood = torch.mean(input * torch.log(output) + (1 - input) * torch.log(1 - output))
    marginal_likelihood_ = bce_loss(output, input)
    kl_divergence = torch.mean(-0.5 * torch.sum((1 + torch.log(torch.square(std))) - torch.square(mu) - torch.square(std), dim=(1)))
    ELBO = marginal_likelihood - kl_divergence
    loss = -ELBO

    return loss

model = VAE()
optimizer = torch.optim.Adam(model.parameters())
schedular = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=10, eta_min=0.00001)
train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=100, shuffle=True)
valid_loader = torch.utils.data.DataLoader(dataset=valid_dataset, batch_size=100, shuffle=False)
epoch_size = 20

# Commented out IPython magic to ensure Python compatibility.
device = "cuda" if torch.cuda.is_available() else "cpu"

model.train()
model.to(device)
# %matplotlib inline

for epoch_i in range(epoch_size):
    epoch_loss = []
    for batch_idx, batch_sample in enumerate(train_loader):
        optimizer.zero_grad()
        data = batch_sample[0].to(device)
        x, mu, std = model(data) #NCHW #60000x 28 x 28

        loss = loss_func(input=data, output=x, mu=mu, std=std)
        epoch_loss.append(loss.item())
        loss.backward()
        optimizer.step()
    print(f"epoch {epoch_i} : {np.mean(epoch_loss)} / lr : {round(schedular.get_last_lr()[0],6)}")
    schedular.step()

    model.eval()
    _x_list = []
    _y_list = []
    _label_list = []
    for batch_idx, batch_sample in enumerate(valid_loader):
        data = batch_sample[0].to(device)
        x, mu, std = model(data)
        z = model.reparameterize(mu, std)
        label = batch_sample[1]

        z = z.detach().cpu().numpy()
        _x_list.extend(z[:, 0])
        _y_list.extend(z[:, 1])
        _label_list.extend(label.detach().cpu().numpy())

    
    plt.figure(figsize=(15, 5))
    plt.subplot(121)
    plt.title(f'epoch {epoch_i}')
    plt.scatter(_x_list, _y_list, s=0.5, c=_label_list, cmap='tab10')

    plt.colorbar()
    plt_img = np.zeros((28*20, 28*20))
    x_iter = np.linspace(-2, 2, 20)
    y_iter = np.linspace(2, -2, 20)
    for x_i, _x in enumerate(x_iter):
        for y_i, _y in enumerate(y_iter):
            z = model.z_layer(torch.Tensor([_x, _y]).unsqueeze(0).cuda())
            _img = model.decode(z)
            plt_img[28 * y_i:28*(y_i + 1), 28 * x_i:28 * (x_i + 1)] = _img[0][0].detach().cpu().numpy()

    plt.subplot(122)
    plt.imshow(plt_img, extent=[-2, 2, -2, 2])

